
<head>
    <!-- add mathjax for tex support -->
<base target="_top">
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    },
    svg: {
      fontCache: 'global'
    }
  };
  </script>
<script id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
<style>
.collapsible{
  display: flex;
  justify-content: center;
  cursor: pointer;
  /* padding: 18px;
  width: 75%; */
  border: none;
  width: 75%;
  margin: 0 auto;
  margin-left: auto;
  margin-right: auto;
  text-align: justify;
  text-justify: inter-word;
}
.collapsible-bio::before{
  font-weight: bold;
  content: "Short Bio";
}

.active, .collapsible-bio:hover {
  /* background-color: #555; */
}

.collapsible-bio:after {
  content: '\002B';
  /* color: white; */
  font-weight: bold;
  float: right;
  /* margin-left: 5px; */
}
/*  */
.collapsible-abstract::before{
  font-weight: bold;
  content: "Abstract";
}

.active, .collapsible-abstract:hover {
  /* background-color: #555; */
}

.collapsible-abstract:after {
  content: '\002B';
  /* color: white; */
  font-weight: bold;
  float: right;
  margin-left: 5px;
}
/*  */
.active:after {
  content: "\2212";
}

.content {
  /* padding: 0 18px; */
  max-height: 0;
  overflow: hidden;
  transition: max-height 0.2s ease-out;
  /* background-color: #f1f1f1; */
  border: none;
  width: 75%;
  margin: 0 auto;
  margin-left: auto;
  margin-right: auto;
  text-align: justify;
  text-justify: inter-word;
}
</style>
</head>

<body>
<ul class="timeline list">
			<li><span class="itemlabel"><span class="hbox llap">Day 1</span></span>
			<p><span class="bf"><span> Tuesday 08 February, 2022</p> Sessions:
			<ul style="list-style-type:disc;">


			<li>Session 1: <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/shenker.html">

				Scott Shenker</a> (UC Berkeley) - Why the Internet Architecture is almost perfect, but our core beliefs about it are entirely wrong</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 2: <a href="https://people.eecs.berkeley.edu/~jordan/">

				Michael I. Jordan</a> (UC Berkeley) - Dr. AI: or How I Learned to Stop Worrying and Love Economics</p></li><br>


				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 3: <a href="https://www.cs.washington.edu/people/faculty/karlin">

				Anna Karlin</a> (University of Washington) - An improved approximation for TSP in the half-integral case (and why Christos is my hero)</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>
				</ul>

		</li>

			<li><span class="itemlabel"><span class="hbox llap">Day 2</span></span>
			<p><span class="bf"><span> Tuesday 15 February, 2022</p> Sessions:
			<ul style="list-style-type:disc;">


			<li>Session 1: <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/shenker.html">

				Scott Shenker</a> (UC Berkeley) - Why the Internet Architecture is almost perfect, but our core beliefs about it are entirely wrong</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 2: <a href="https://people.eecs.berkeley.edu/~jordan/">

				Michael I. Jordan</a> (UC Berkeley) - Dr. AI: or How I Learned to Stop Worrying and Love Economics</p></li><br>


				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 3: <a href="https://www.cs.washington.edu/people/faculty/karlin">

				Anna Karlin</a> (University of Washington) - An improved approximation for TSP in the half-integral case (and why Christos is my hero)</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>
				</ul>

		</li>

			<li><span class="itemlabel"><span class="hbox llap">Day 3</span></span>
			<p><span class="bf"><span> Tuesday 22 February, 2022</p> Sessions:
			<ul style="list-style-type:disc;">


			<li>Session 1: <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/shenker.html">

				Scott Shenker</a> (UC Berkeley) - Why the Internet Architecture is almost perfect, but our core beliefs about it are entirely wrong</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 2: <a href="https://people.eecs.berkeley.edu/~jordan/">

				Michael I. Jordan</a> (UC Berkeley) - Dr. AI: or How I Learned to Stop Worrying and Love Economics</p></li><br>


				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 3: <a href="https://www.cs.washington.edu/people/faculty/karlin">

				Anna Karlin</a> (University of Washington) - An improved approximation for TSP in the half-integral case (and why Christos is my hero)</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>
				</ul>

		</li>

			<li><span class="itemlabel"><span class="hbox llap">Day 4</span></span>
			<p><span class="bf"><span> Tuesday 01 March, 2022</p> Sessions:
			<ul style="list-style-type:disc;">


			<li>Session 1: <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/shenker.html">

				Scott Shenker</a> (UC Berkeley) - Why the Internet Architecture is almost perfect, but our core beliefs about it are entirely wrong</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 2: <a href="https://people.eecs.berkeley.edu/~jordan/">

				Michael I. Jordan</a> (UC Berkeley) - Dr. AI: or How I Learned to Stop Worrying and Love Economics</p></li><br>


				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 3: <a href="https://www.cs.washington.edu/people/faculty/karlin">

				Anna Karlin</a> (University of Washington) - An improved approximation for TSP in the half-integral case (and why Christos is my hero)</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>
				</ul>

		</li>

			<li><span class="itemlabel"><span class="hbox llap">Day 5</span></span>
			<p><span class="bf"><span> Tuesday 08 March, 2022</p> Sessions:
			<ul style="list-style-type:disc;">


			<li>Session 1: <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/shenker.html">

				Scott Shenker</a> (UC Berkeley) - Why the Internet Architecture is almost perfect, but our core beliefs about it are entirely wrong</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 2: <a href="https://people.eecs.berkeley.edu/~jordan/">

				Michael I. Jordan</a> (UC Berkeley) - Dr. AI: or How I Learned to Stop Worrying and Love Economics</p></li><br>


				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 3: <a href="https://www.cs.washington.edu/people/faculty/karlin">

				Anna Karlin</a> (University of Washington) - An improved approximation for TSP in the half-integral case (and why Christos is my hero)</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>
				</ul>

		</li>

			<li><span class="itemlabel"><span class="hbox llap">Day 6</span></span>
			<p><span class="bf"><span> Tuesday 15 March, 2022</p> Sessions:
			<ul style="list-style-type:disc;">


			<li>Session 1: <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/shenker.html">

				Scott Shenker</a> (UC Berkeley) - Why the Internet Architecture is almost perfect, but our core beliefs about it are entirely wrong</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 2: <a href="https://people.eecs.berkeley.edu/~jordan/">

				Michael I. Jordan</a> (UC Berkeley) - Dr. AI: or How I Learned to Stop Worrying and Love Economics</p></li><br>


				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 3: <a href="https://www.cs.washington.edu/people/faculty/karlin">

				Anna Karlin</a> (University of Washington) - An improved approximation for TSP in the half-integral case (and why Christos is my hero)</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>
				</ul>

		</li>

			<li><span class="itemlabel"><span class="hbox llap">Day 7</span></span>
			<p><span class="bf"><span> Tuesday 22 March, 2022</p> Sessions:
			<ul style="list-style-type:disc;">


			<li>Session 1: <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/shenker.html">

				Scott Shenker</a> (UC Berkeley) - Why the Internet Architecture is almost perfect, but our core beliefs about it are entirely wrong</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 2: <a href="https://people.eecs.berkeley.edu/~jordan/">

				Michael I. Jordan</a> (UC Berkeley) - Dr. AI: or How I Learned to Stop Worrying and Love Economics</p></li><br>


				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 3: <a href="https://www.cs.washington.edu/people/faculty/karlin">

				Anna Karlin</a> (University of Washington) - An improved approximation for TSP in the half-integral case (and why Christos is my hero)</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>
				</ul>

		</li>

			<li><span class="itemlabel"><span class="hbox llap">Day 8</span></span>
			<p><span class="bf"><span> Tuesday 29 March, 2022</p> Sessions:
			<ul style="list-style-type:disc;">


			<li>Session 1: <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/shenker.html">

				Scott Shenker</a> (UC Berkeley) - Why the Internet Architecture is almost perfect, but our core beliefs about it are entirely wrong</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 2: <a href="https://people.eecs.berkeley.edu/~jordan/">

				Michael I. Jordan</a> (UC Berkeley) - Dr. AI: or How I Learned to Stop Worrying and Love Economics</p></li><br>


				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 3: <a href="https://www.cs.washington.edu/people/faculty/karlin">

				Anna Karlin</a> (University of Washington) - An improved approximation for TSP in the half-integral case (and why Christos is my hero)</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>
				</ul>

		</li>

			<li><span class="itemlabel"><span class="hbox llap">Day 9</span></span>
			<p><span class="bf"><span> Tuesday 05 April, 2022</p> Sessions:
			<ul style="list-style-type:disc;">


			<li>Session 1: <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/shenker.html">

				Scott Shenker</a> (UC Berkeley) - Why the Internet Architecture is almost perfect, but our core beliefs about it are entirely wrong</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 2: <a href="https://people.eecs.berkeley.edu/~jordan/">

				Michael I. Jordan</a> (UC Berkeley) - Dr. AI: or How I Learned to Stop Worrying and Love Economics</p></li><br>


				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 3: <a href="https://www.cs.washington.edu/people/faculty/karlin">

				Anna Karlin</a> (University of Washington) - An improved approximation for TSP in the half-integral case (and why Christos is my hero)</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>
				</ul>

		</li>

			<li><span class="itemlabel"><span class="hbox llap">Day 10</span></span>
			<p><span class="bf"><span> Tuesday 12 April, 2022</p> Sessions:
			<ul style="list-style-type:disc;">


			<li>Session 1: <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/shenker.html">

				Scott Shenker</a> (UC Berkeley) - Why the Internet Architecture is almost perfect, but our core beliefs about it are entirely wrong</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 2: <a href="https://people.eecs.berkeley.edu/~jordan/">

				Michael I. Jordan</a> (UC Berkeley) - Dr. AI: or How I Learned to Stop Worrying and Love Economics</p></li><br>


				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 3: <a href="https://www.cs.washington.edu/people/faculty/karlin">

				Anna Karlin</a> (University of Washington) - An improved approximation for TSP in the half-integral case (and why Christos is my hero)</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>
				</ul>

		</li>

			<li><span class="itemlabel"><span class="hbox llap">Day 11</span></span>
			<p><span class="bf"><span> Tuesday 19 April, 2022</p> Sessions:
			<ul style="list-style-type:disc;">


			<li>Session 1: <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/shenker.html">

				Scott Shenker</a> (UC Berkeley) - Why the Internet Architecture is almost perfect, but our core beliefs about it are entirely wrong</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 2: <a href="https://people.eecs.berkeley.edu/~jordan/">

				Michael I. Jordan</a> (UC Berkeley) - Dr. AI: or How I Learned to Stop Worrying and Love Economics</p></li><br>


				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 3: <a href="https://www.cs.washington.edu/people/faculty/karlin">

				Anna Karlin</a> (University of Washington) - An improved approximation for TSP in the half-integral case (and why Christos is my hero)</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>
				</ul>

		</li>

			<li><span class="itemlabel"><span class="hbox llap">Day 12</span></span>
			<p><span class="bf"><span> Tuesday 26 April, 2022</p> Sessions:
			<ul style="list-style-type:disc;">


			<li>Session 1: <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/shenker.html">

				Scott Shenker</a> (UC Berkeley) - Why the Internet Architecture is almost perfect, but our core beliefs about it are entirely wrong</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 2: <a href="https://people.eecs.berkeley.edu/~jordan/">

				Michael I. Jordan</a> (UC Berkeley) - Dr. AI: or How I Learned to Stop Worrying and Love Economics</p></li><br>


				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 3: <a href="https://www.cs.washington.edu/people/faculty/karlin">

				Anna Karlin</a> (University of Washington) - An improved approximation for TSP in the half-integral case (and why Christos is my hero)</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>
				</ul>

		</li>

			<li><span class="itemlabel"><span class="hbox llap">Day 13</span></span>
			<p><span class="bf"><span> Tuesday 03 May, 2022</p> Sessions:
			<ul style="list-style-type:disc;">


			<li>Session 1: <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/shenker.html">

				Scott Shenker</a> (UC Berkeley) - Why the Internet Architecture is almost perfect, but our core beliefs about it are entirely wrong</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 2: <a href="https://people.eecs.berkeley.edu/~jordan/">

				Michael I. Jordan</a> (UC Berkeley) - Dr. AI: or How I Learned to Stop Worrying and Love Economics</p></li><br>


				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 3: <a href="https://www.cs.washington.edu/people/faculty/karlin">

				Anna Karlin</a> (University of Washington) - An improved approximation for TSP in the half-integral case (and why Christos is my hero)</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>
				</ul>

		</li>

			<li><span class="itemlabel"><span class="hbox llap">Day 14</span></span>
			<p><span class="bf"><span> Tuesday 10 May, 2022</p> Sessions:
			<ul style="list-style-type:disc;">


			<li>Session 1: <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/shenker.html">

				Scott Shenker</a> (UC Berkeley) - Why the Internet Architecture is almost perfect, but our core beliefs about it are entirely wrong</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 2: <a href="https://people.eecs.berkeley.edu/~jordan/">

				Michael I. Jordan</a> (UC Berkeley) - Dr. AI: or How I Learned to Stop Worrying and Love Economics</p></li><br>


				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 3: <a href="https://www.cs.washington.edu/people/faculty/karlin">

				Anna Karlin</a> (University of Washington) - An improved approximation for TSP in the half-integral case (and why Christos is my hero)</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>
				</ul>

		</li>

			<li><span class="itemlabel"><span class="hbox llap">Day 15</span></span>
			<p><span class="bf"><span> Tuesday 17 May, 2022</p> Sessions:
			<ul style="list-style-type:disc;">


			<li>Session 1: <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/shenker.html">

				Scott Shenker</a> (UC Berkeley) - Why the Internet Architecture is almost perfect, but our core beliefs about it are entirely wrong</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 2: <a href="https://people.eecs.berkeley.edu/~jordan/">

				Michael I. Jordan</a> (UC Berkeley) - Dr. AI: or How I Learned to Stop Worrying and Love Economics</p></li><br>


				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 3: <a href="https://www.cs.washington.edu/people/faculty/karlin">

				Anna Karlin</a> (University of Washington) - An improved approximation for TSP in the half-integral case (and why Christos is my hero)</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>
				</ul>

		</li>

			<li><span class="itemlabel"><span class="hbox llap">Day 16</span></span>
			<p><span class="bf"><span> Tuesday 24 May, 2022</p> Sessions:
			<ul style="list-style-type:disc;">


			<li>Session 1: <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/shenker.html">

				Scott Shenker</a> (UC Berkeley) - Why the Internet Architecture is almost perfect, but our core beliefs about it are entirely wrong</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 2: <a href="https://people.eecs.berkeley.edu/~jordan/">

				Michael I. Jordan</a> (UC Berkeley) - Dr. AI: or How I Learned to Stop Worrying and Love Economics</p></li><br>


				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 3: <a href="https://www.cs.washington.edu/people/faculty/karlin">

				Anna Karlin</a> (University of Washington) - An improved approximation for TSP in the half-integral case (and why Christos is my hero)</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>
				</ul>

		</li>

			<li><span class="itemlabel"><span class="hbox llap">Day 17</span></span>
			<p><span class="bf"><span> Tuesday 31 May, 2022</p> Sessions:
			<ul style="list-style-type:disc;">


			<li>Session 1: <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/shenker.html">

				Scott Shenker</a> (UC Berkeley) - Why the Internet Architecture is almost perfect, but our core beliefs about it are entirely wrong</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 2: <a href="https://people.eecs.berkeley.edu/~jordan/">

				Michael I. Jordan</a> (UC Berkeley) - Dr. AI: or How I Learned to Stop Worrying and Love Economics</p></li><br>


				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>

			<li>Session 3: <a href="https://www.cs.washington.edu/people/faculty/karlin">

				Anna Karlin</a> (University of Washington) - An improved approximation for TSP in the half-integral case (and why Christos is my hero)</li><br>



				<button class="collapsible collapsible-abstract"></button>

				<div class="content">

					<p>

					A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others.

					</p>

				</div>

					

				<button class="collapsible collapsible-bio"></button>

				<div class="content">

					<p>

					Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models

					</p>

				</div>
				</ul>

		</li>

	</li>
</ul>
<script>
var coll = document.getElementsByClassName("collapsible");
var i;

for (i = 0; i < coll.length; i++) {
  coll[i].addEventListener("click", function() {
    this.classList.toggle("active");
    var content = this.nextElementSibling;
    if (content.style.maxHeight){
      content.style.maxHeight = null;
    } else {
      content.style.maxHeight = content.scrollHeight + "px";
    }
  });
}
</script>
</body>
