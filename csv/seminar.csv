date,time,speaker,url,affiliation,title,bio,abstract,imgfile,location,zoom,connected-papers
10/02/22,13:30:00,Niao He,https://odi.inf.ethz.ch/niaohe.html,ETH,Universal Acceleration for Minimax Optimization,"Niao He is currently an Assistant Professor in the Department of Computer Science at ETH Zurich,  where she leads the Optimization and Decision Intelligence (ODI) Group. She is an ELLIS Scholar and a core faculty member of ETH AI Center. Previously, she was an assistant professor at the University of Illinois at Urbana-Champaign from 2016 to 2020. Before that, she received her Ph.D. degree in Operations Research from Georgia Institute of Technology in 2015. Her research interests lie in the intersection of optimization and machine learning, with a primary focus on minimax optimization and reinforcement learning.","We present a generic acceleration recipe for smooth minimax optimization. By simply combing with existing solvers such as extra-gradient method as the workhorse for subproblems,  one can achieve best-known convergence rates for minimax optimization in various regimes such as the strongly-convex-(strongly)-concave,  nonconvex-(strongly)-concave settings.  Our key idea is largely inspired by the Catalyst framework in [Lin, Mairal, and Harchaoui, 2015] and can be framed as an inexact accelerated proximal point algorithm. The framework can be extended to solving finite-sum minimax problems and special classes of nonconvex-nonconcave minimax problems with best-known rates.",niao-he.jpg,Room 116 ,https://berkeley.zoom.us/my/simonszoom2,
03/02/22,13:30:00,Jacob Abernethy,https://faculty.cc.gatech.edu/~jabernethy9/,GA Tech,Building Optimization Algorithms by Playing Games ,"Jacob Abernethy is an Associate Professor in the College of Computing at Georgia Tech. In October 2011 he finished a PhD in the Division of Computer Science at the University of California at Berkeley, spent two years as a Simons postdoctoral fellow at UPenn, and held a faculty job at the University of Michigan for four years before joining Georgia Tech. Abernethy's primary interest is in Machine Learning, with a particular focus in sequential decision making, online learning, online algorithms and adversarial learning models ","A very popular trick for solving certain types of optimization problems is this: write your objective as the solution of a two-player zero-sum game, endow both players with an appropriate learning algorithm, watch how the opponents compete, and extract an (approximate) solution from the actions/decisions taken by the players throughout the process. This approach is very generic and provides a natural template to produce new and interesting algorithms. I will describe this framework and show how it applies in several scenarios, and describe recent work drawing connections to classical algorithms including Frank-Wolfe, Nesterov Accelerated Gradient Descent, and many others. ",jake.jpeg,Room 116,https://berkeley.zoom.us/my/simonszoom2,
17/02/22,14:00:00,Simina Branzei,https://simina.info/,Purdue,Multiplayer learning in multi-armed bandits and markets,"Simina Branzei is an assistant professor at Purdue University. She completed her Ph.d. at Aarhus University in Denmark and afterwards was a research fellow at Simons and postdoctoral fellow at the Hebrew University of Jerusalem. Her research interests are in algorithmic game theory, learning, and more generally artificial intelligence and theoretical computer science.","Consider a two player multi-armed bandit problem, where one arm has a known success probability, while the other arm does not. In every round, each player pulls an arm, gets the reward from the arm they pulled, and observes the action of the other player but not their reward. The model is related to the economics literature on strategic experimentation, where usually players observe each other's rewards. 

We show that two competing players explore less than a single player with an optimal strategy, while cooperating players explore more. Neutral players learn from each other, receiving strictly higher rewards than if they played by themselves. Both competing and neutral players settle on the same arm in the long term.

 

I will also discuss exchange and production markets with additive valuations, when players learn to bid using proportional response dynamics. In the production market, this dynamic leads to growth of the market in the long term, but also creates growing inequality between the players. In the exchange market, the proportional response dynamic converges to market equilibria. This resolves an open question about the exchange market, where tatonnement does not converge to market equilibria and no natural process leading to equilibria was known.

This is based on joint works with Peres and Devanur, Mehta, Nisan, and Rabani.",simina.png,Room 116,https://berkeley.zoom.us/my/simonszoom2,
